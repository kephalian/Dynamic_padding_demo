# Dynamic_padding_demo
Processing the dataset and Dynamic padding demonstration. Modified from one available in HggingFace site at
(https://huggingface.co/learn/nlp-course/chapter3/2?fw=pt)[https://huggingface.co/learn/nlp-course/chapter3/2?fw=pt].

### It is simple enough for everyone to understand.

My Notebook can be found (here)[https://github.com/kephalian/Dynamic_padding_demo/blob/main/Processing_the_data_(PyTorch)(1).ipynb]. 


This notebook is my simplification of the Tokenizers demo, on how Tokenizers work found in Hugging Face Hub NLP Course, [Found Here https://huggingface.co/learn/nlp-course/chapter2/2?fw=p](https://huggingface.co/learn/nlp-course/chapter3/2?fw=p)

# Probably the first thing they should teach you to save your work! (but they don't)

##### OTHER ITEMS OF INTEREST IN THIS REPO- 

[Loading a Hugging Face Transformer model and tokenizer from DISC Offline](https://github.com/kephalian/Tokenizers_demo/blob/main/Load_model_from_disc.md)


[SAVING a Hugging Face Transformer model and tokenizer to DISC FOR offline use](https://github.com/kephalian/Tokenizers_demo/blob/main/saving_a_model_to_disc.md)



Pull requests are solicited!
Prof. Dr. Santhosh Kumar Rajamani
MAEER MIT Pune's MIMER Medical College
Find me @ [ORCID](https://orcid.org/0000-0001-6552-5578)
        @ [Google Scholar](https://scholar.google.com/citations?hl=en&user=lU7vGgQAAAAJ)


